{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Importing Dataset"
      ],
      "metadata": {
        "id": "EPqHiymBOvaU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "teedWyyfOfwa",
        "outputId": "beff9632-bc4d-420b-d60f-7ac7097e1ad5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Importing Libraries"
      ],
      "metadata": {
        "id": "AnAZI4J8Nw0y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "qhEpRna4NaZw"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Preprocessing"
      ],
      "metadata": {
        "id": "kkS_Gqz8N9x-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Training Image preprocessing"
      ],
      "metadata": {
        "id": "fpXf0EfaOSVl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_set = tf.keras.utils.image_dataset_from_directory(\n",
        "    '/content/drive/MyDrive/Fruit_Vegetable_Data/train',\n",
        "    labels=\"inferred\",\n",
        "    label_mode=\"categorical\",\n",
        "    class_names=None,\n",
        "    color_mode=\"rgb\",\n",
        "    batch_size=32,\n",
        "    image_size=(64, 64),\n",
        "    shuffle=True,\n",
        "    seed=None,\n",
        "    validation_split=None,\n",
        "    subset=None,\n",
        "    interpolation=\"bilinear\",\n",
        "    follow_links=False,\n",
        "    crop_to_aspect_ratio=False\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hnvgGGF0N3Jl",
        "outputId": "c8e85696-74cd-466e-df9b-4191056be1f3"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3115 files belonging to 36 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Validation Image Preprocessing"
      ],
      "metadata": {
        "id": "IAs7Lah2RGID"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "validation_set = tf.keras.utils.image_dataset_from_directory(\n",
        "    '/content/drive/MyDrive/Fruit_Vegetable_Data/validation',\n",
        "    labels=\"inferred\",\n",
        "    label_mode=\"categorical\",\n",
        "    class_names=None,\n",
        "    color_mode=\"rgb\",\n",
        "    batch_size=32,\n",
        "    image_size=(64, 64),\n",
        "    shuffle=True,\n",
        "    seed=None,\n",
        "    validation_split=None,\n",
        "    subset=None,\n",
        "    interpolation=\"bilinear\",\n",
        "    follow_links=False,\n",
        "    crop_to_aspect_ratio=False\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CnbKBGYlOAWE",
        "outputId": "80a821d7-a2b9-4c94-b7fd-8672bec1b364"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 359 files belonging to 36 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Building Model"
      ],
      "metadata": {
        "id": "LcMkdEqBSgmW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn = tf.keras.models.Sequential()"
      ],
      "metadata": {
        "id": "LkZJA0tnSikT"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Building Convolution Layer"
      ],
      "metadata": {
        "id": "Wbg4LaVQS5zf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Conv2D(filters=64,kernel_size=3,activation='relu',input_shape=[64,64,3]))\n",
        "#cnn.add(tf.keras.layers.Conv2D(filters=32,kernel_size=3,activation='relu'))\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2))"
      ],
      "metadata": {
        "id": "3-rffTpxS4GL"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Conv2D(filters=64,kernel_size=3,activation='relu'))\n",
        "#cnn.add(tf.keras.layers.Conv2D(filters=64,kernel_size=3,activation='relu'))\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2))"
      ],
      "metadata": {
        "id": "CRCe2nsXTntC"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Dropout(0.5))#To avoid overfitting"
      ],
      "metadata": {
        "id": "xPcZqGmFUDOP"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Flatten())"
      ],
      "metadata": {
        "id": "cAIu4zsNUJ6m"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Dense(units=128,activation='relu'))"
      ],
      "metadata": {
        "id": "SQAl1U-XUNYe"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Output Layer\n",
        "cnn.add(tf.keras.layers.Dense(units=36,activation='softmax'))"
      ],
      "metadata": {
        "id": "XYG3iOD4UYS2"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Compiling and Training Phase"
      ],
      "metadata": {
        "id": "298RbI_HUzSM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.compile(optimizer='rmsprop',loss='categorical_crossentropy',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "rzYfTTGOUp-x"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_history=cnn.fit(x=training_set,validation_data=validation_set,epochs=30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wx1SBCFlVLBZ",
        "outputId": "fda15ca6-0621-4509-e38b-4939fa84b6b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "18/98 [====>.........................] - ETA: 14:07 - loss: 33.7628 - accuracy: 0.0382"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Saving Model"
      ],
      "metadata": {
        "id": "pFO9eJP_V9fI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.save('trained_model.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lLMqrZc3V01l",
        "outputId": "ba72f18e-8c46-4765-d528-ab33d0c3078e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_history.history #dictionary"
      ],
      "metadata": {
        "id": "miCSzqD8WbfW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Recording History in json\n",
        "import json\n",
        "with open('training_hist.json','w') as f:\n",
        "  json.dump(training_history.history,f)"
      ],
      "metadata": {
        "id": "5gBim-LIWJvr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(training_history.history.keys())"
      ],
      "metadata": {
        "id": "eqQxYufAXB9G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Calculating Accuracy of Model Achieved on Validation set\n"
      ],
      "metadata": {
        "id": "1EHtmkGRXDAL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Validation set Accuracy: {} %\".format(training_history.history['val_accuracy'][-1]*100))"
      ],
      "metadata": {
        "id": "Le8keMceXJhX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}